# Scrape with Compassion

You can damage websites by scraping irresponsibly. You can get banned by not following a site's rules. You can cause both yourself needless work and a website needless pain by failing to use their API. So, do your homework to see if scraping is necessary, then scrape with kindness and permission.

* In `settings.py` enable the `DOWNLOAD_DELAY` option to space out your downloads.
* In `settings.py` enable the `USER_AGENT` option so you look more like a browser than a robot.
* For professional work, try using ScrapingHub.com and their free limited plan.
* Search for an API for the website before trying to scrape the site.
* Read the Terms and Conditions of the website before scraping it to see they specify conditions for scraping.
* Data from web scraping can be used for nefarious ends, so exercise some judgment.
* In general, do not disable `ROBOTSTXT_OBEY` unless you have good reason to do so.

